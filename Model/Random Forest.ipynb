{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert positive to 1 and negative to 0\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df_num = ordinal_encoder.fit_transform(df[['sentiment']])\n",
    "df['num_sentiment'] = df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove html coding\n",
    "df['review'] = df['review'].str.replace('<.*?>','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all puncuation and symbols\n",
    "df['review'] = df['review'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything lower case\n",
    "df['review'] = df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data with Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsw = df.copy()\n",
    "df_wosw = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize\n",
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    \n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsw['lemma_review'] = df_wsw.review.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv file\n",
    "df_wsw.to_csv('df_wsw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df_wsw = pd.read_csv('df_wsw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>num_sentiment</th>\n",
       "      <th>lemma_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>one of the other reviewer ha mentioned that af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i thought this wa a wonderful way to spend tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basically there a family where a little boy ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  num_sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...            1.0   \n",
       "1  a wonderful little production the filming tech...            1.0   \n",
       "2  i thought this was a wonderful way to spend ti...            1.0   \n",
       "3  basically theres a family where a little boy j...            0.0   \n",
       "4  petter matteis love in the time of money is a ...            1.0   \n",
       "\n",
       "                                        lemma_review  \n",
       "0  one of the other reviewer ha mentioned that af...  \n",
       "1  a wonderful little production the filming tech...  \n",
       "2  i thought this wa a wonderful way to spend tim...  \n",
       "3  basically there a family where a little boy ja...  \n",
       "4  petter matteis love in the time of money is a ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wsw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Data without Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "all_stopwords = sp.Defaults.stop_words\n",
    "## After seeing the word counts, update stop words\n",
    "sp.Defaults.stop_words |= {'movie', 'film', 'like'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wosw['review'] = df_wosw['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (all_stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wosw['lemma_review'] = df_wosw.review.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv file\n",
    "df_wosw.to_csv('df_wosw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df_wosw = pd.read_csv('df_wosw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>num_sentiment</th>\n",
       "      <th>lemma_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewers mentioned watching 1 oz episode youl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reviewer mentioned watching 1 oz episode youll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  num_sentiment  \\\n",
       "0  reviewers mentioned watching 1 oz episode youl...            1.0   \n",
       "1  wonderful little production filming technique ...            1.0   \n",
       "2  thought wonderful way spend time hot summer we...            1.0   \n",
       "3  basically theres family little boy jake thinks...            0.0   \n",
       "4  petter matteis love time money visually stunni...            1.0   \n",
       "\n",
       "                                        lemma_review  \n",
       "0  reviewer mentioned watching 1 oz episode youll...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wosw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Build Model with dataset with stopwords using Sentiment Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to get subjectivity and polarity\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def Subjectivity(text):\n",
    "    \n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def Polarity(text):\n",
    "    \n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two columns 'Subjectivity' and 'Polarity'\n",
    "df_wsw['Subjectivity'] = df_wsw['review'].apply(Subjectivity)\n",
    "df_wsw['Polarity'] = df_wsw['review'].apply(Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to get sentiment scores\n",
    "def SIA(text):\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the sentiment scores for each review\n",
    "compound = []\n",
    "neg = []\n",
    "pos = []\n",
    "neu = []\n",
    "Sentiment = 0\n",
    "\n",
    "for i in range(0, len(df_wsw['review'])):\n",
    "    \n",
    "    Sentiment = SIA(df_wsw['review'][i])\n",
    "\n",
    "    compound.append(Sentiment['compound']) \n",
    "    neg.append(Sentiment['neg'])\n",
    "    pos.append(Sentiment['pos'])\n",
    "    neu.append(Sentiment['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the sentiment scores in the merge data set\n",
    "df_wsw['Compound'] = compound\n",
    "df_wsw['Negative'] = neg\n",
    "df_wsw['Neutral'] = neu\n",
    "df_wsw['Positive'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv file\n",
    "df_wsw.to_csv('IMDB Dataset with Sentiment Score and stopwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset with sentiment score\n",
    "df_wsw_sentiment = pd.read_csv('IMDB Dataset with Sentiment Score and stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>num_sentiment</th>\n",
       "      <th>lemma_review</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>one of the other reviewer ha mentioned that af...</td>\n",
       "      <td>0.490369</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>-0.9916</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>0.559343</td>\n",
       "      <td>0.111490</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i thought this wa a wonderful way to spend tim...</td>\n",
       "      <td>0.640769</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basically there a family where a little boy ja...</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>-0.060937</td>\n",
       "      <td>-0.9117</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>0.452916</td>\n",
       "      <td>0.217952</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  num_sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...            1.0   \n",
       "1  a wonderful little production the filming tech...            1.0   \n",
       "2  i thought this was a wonderful way to spend ti...            1.0   \n",
       "3  basically theres a family where a little boy j...            0.0   \n",
       "4  petter matteis love in the time of money is a ...            1.0   \n",
       "\n",
       "                                        lemma_review  Subjectivity  Polarity  \\\n",
       "0  one of the other reviewer ha mentioned that af...      0.490369  0.023433   \n",
       "1  a wonderful little production the filming tech...      0.559343  0.111490   \n",
       "2  i thought this wa a wonderful way to spend tim...      0.640769  0.346324   \n",
       "3  basically there a family where a little boy ja...      0.454167 -0.060937   \n",
       "4  petter matteis love in the time of money is a ...      0.452916  0.217952   \n",
       "\n",
       "   Compound  Negative  Neutral  Positive  \n",
       "0   -0.9916     0.182    0.752     0.066  \n",
       "1    0.9657     0.053    0.766     0.180  \n",
       "2    0.9579     0.116    0.675     0.210  \n",
       "3   -0.9117     0.129    0.808     0.063  \n",
       "4    0.9744     0.052    0.800     0.148  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wsw_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "- Train: 25000 \n",
      "- Validation: 12500 \n",
      "- Test: 12500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = df_wsw_sentiment.drop(['num_sentiment', 'review', 'lemma_review'], axis=1)\n",
    "label = df_wsw_sentiment['num_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size = 0.50, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Data distribution:\\n- Train: {} \\n- Validation: {} \\n- Test: {}\".format(len(X_train),len(X_val),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf, X_train, y_train.values.ravel(), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.772  0.767  0.7704 0.7688 0.7658]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7688"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to print results\n",
    "def print_results(results):\n",
    "    \n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    \n",
    "    for mean, params in zip(means, results.cv_results_['params']):\n",
    "        \n",
    "        print('{} for {}'.format(round(mean, 5), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV to choose the best parameters        \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridsearch(x_train, y_train):\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    parameters = {\n",
    "        \n",
    "    'n_estimators': [5, 50, 100, 500, 1000, 3000],\n",
    "    'max_depth': [2, 10, 50, None]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    cv = GridSearchCV(rf, parameters)\n",
    "    cv.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 10, 'n_estimators': 3000}\n",
      "\n",
      "0.74044 for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.76888 for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.77008 for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.77016 for {'max_depth': 2, 'n_estimators': 500}\n",
      "0.76984 for {'max_depth': 2, 'n_estimators': 1000}\n",
      "0.76972 for {'max_depth': 2, 'n_estimators': 3000}\n",
      "0.76584 for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.77664 for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.77696 for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.7766 for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.77712 for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.77732 for {'max_depth': 10, 'n_estimators': 3000}\n",
      "0.74028 for {'max_depth': 50, 'n_estimators': 5}\n",
      "0.76792 for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.7688 for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.77116 for {'max_depth': 50, 'n_estimators': 500}\n",
      "0.77248 for {'max_depth': 50, 'n_estimators': 1000}\n",
      "0.77188 for {'max_depth': 50, 'n_estimators': 3000}\n",
      "0.74028 for {'max_depth': None, 'n_estimators': 5}\n",
      "0.76792 for {'max_depth': None, 'n_estimators': 50}\n",
      "0.7688 for {'max_depth': None, 'n_estimators': 100}\n",
      "0.77132 for {'max_depth': None, 'n_estimators': 500}\n",
      "0.77248 for {'max_depth': None, 'n_estimators': 1000}\n",
      "0.77192 for {'max_depth': None, 'n_estimators': 3000}\n"
     ]
    }
   ],
   "source": [
    "print_results(gridsearch(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use validation set to select the best parameters\n",
    "rf1 = RandomForestClassifier(n_estimators=3000, max_depth=10)\n",
    "rf1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, max_depth=50)\n",
    "rf2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=500, max_depth=2)\n",
    "rf3.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators=1000, max_depth=None)\n",
    "rf4.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "def performance(rf1, rf2, rf3, rf4, X_val):\n",
    "    \n",
    "    for mdl in [rf1,rf2,rf3, rf4]:\n",
    "        \n",
    "        y_pred = mdl.predict(X_val)\n",
    "        \n",
    "        accuracy = round(accuracy_score(y_val,y_pred), 3)\n",
    "        precision = round(precision_score(y_val,y_pred), 3)\n",
    "        recall = round(recall_score(y_val,y_pred), 3)\n",
    "        f1 = round(f1_score(y_val,y_pred), 3)\n",
    "    \n",
    "        print('MAX DEPTH: {}, # OF EST: {} -- Accuracy: {}, Precision: {}, Recall: {}, F1-Score: {}'.format(mdl.max_depth,\n",
    "                                                                                                            mdl.n_estimators,\n",
    "                                                                                                            accuracy,\n",
    "                                                                                                            precision,\n",
    "                                                                                                            recall,\n",
    "                                                                                                            f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 10, # OF EST: 3000 -- Accuracy: 0.77, Precision: 0.767, Recall: 0.768, F1-Score: 0.768\n",
      "MAX DEPTH: 50, # OF EST: 1000 -- Accuracy: 0.762, Precision: 0.758, Recall: 0.76, F1-Score: 0.759\n",
      "MAX DEPTH: 2, # OF EST: 500 -- Accuracy: 0.767, Precision: 0.77, Recall: 0.751, F1-Score: 0.76\n",
      "MAX DEPTH: None, # OF EST: 1000 -- Accuracy: 0.762, Precision: 0.759, Recall: 0.759, F1-Score: 0.759\n"
     ]
    }
   ],
   "source": [
    "performance(rf1, rf2, rf3, rf4, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_performance(rf, X_test):\n",
    "    \n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    accuracy = round(accuracy_score(y_test,y_pred), 3)\n",
    "    precision = round(precision_score(y_test,y_pred), 3)\n",
    "    recall = round(recall_score(y_test,y_pred), 3)\n",
    "    f1 = round(f1_score(y_test,y_pred), 3)\n",
    "    \n",
    "    print('MAX DEPTH: {}, # OF EST: {} -- Accuracy: {}, Precison: {}, Recall: {}, F1-Score: {}'.format(rf.max_depth,\n",
    "                                                                                                       rf.n_estimators,\n",
    "                                                                                                       accuracy,\n",
    "                                                                                                       precision,\n",
    "                                                                                                       recall,\n",
    "                                                                                                       f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 10, # OF EST: 3000 -- Accuracy: 0.774, Precison: 0.778, Recall: 0.778, F1-Score: 0.778\n"
     ]
    }
   ],
   "source": [
    "final_performance(rf1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Build Model with dataset without stopwords using Sentiment Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Create Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two columns 'Subjectivity' and 'Polarity'\n",
    "df_wosw['Subjectivity'] = df_wosw['review'].apply(Subjectivity)\n",
    "df_wosw['Polarity'] = df_wosw['review'].apply(Polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the sentiment scores for each review\n",
    "compound = []\n",
    "neg = []\n",
    "pos = []\n",
    "neu = []\n",
    "Sentiment = 0\n",
    "\n",
    "for i in range(0, len(df_wosw['review'])):\n",
    "    \n",
    "    Sentiment = SIA(df_wosw['review'][i])\n",
    "\n",
    "    compound.append(Sentiment['compound']) \n",
    "    neg.append(Sentiment['neg'])\n",
    "    pos.append(Sentiment['pos'])\n",
    "    neu.append(Sentiment['neu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the sentiment scores in the merge data set\n",
    "df_wosw['Compound'] = compound\n",
    "df_wosw['Negative'] = neg\n",
    "df_wosw['Neutral'] = neu\n",
    "df_wosw['Positive'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save as csv file\n",
    "df_wosw.to_csv('IMDB Dataset with Sentiment Score and without stopwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset with sentiment score\n",
    "df_wosw_sentiment = pd.read_csv('IMDB Dataset with Sentiment Score and without stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>num_sentiment</th>\n",
       "      <th>lemma_review</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reviewers mentioned watching 1 oz episode youl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reviewer mentioned watching 1 oz episode youll...</td>\n",
       "      <td>0.522282</td>\n",
       "      <td>0.025685</td>\n",
       "      <td>-0.9948</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>0.592222</td>\n",
       "      <td>0.122778</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>0.692381</td>\n",
       "      <td>0.349048</td>\n",
       "      <td>0.9666</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>-0.105357</td>\n",
       "      <td>-0.9450</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>0.442848</td>\n",
       "      <td>0.228697</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  num_sentiment  \\\n",
       "0  reviewers mentioned watching 1 oz episode youl...            1.0   \n",
       "1  wonderful little production filming technique ...            1.0   \n",
       "2  thought wonderful way spend time hot summer we...            1.0   \n",
       "3  basically theres family little boy jake thinks...            0.0   \n",
       "4  petter matteis love time money visually stunni...            1.0   \n",
       "\n",
       "                                        lemma_review  Subjectivity  Polarity  \\\n",
       "0  reviewer mentioned watching 1 oz episode youll...      0.522282  0.025685   \n",
       "1  wonderful little production filming technique ...      0.592222  0.122778   \n",
       "2  thought wonderful way spend time hot summer we...      0.692381  0.349048   \n",
       "3  basically there family little boy jake think t...      0.471429 -0.105357   \n",
       "4  petter matteis love time money visually stunni...      0.442848  0.228697   \n",
       "\n",
       "   Compound  Negative  Neutral  Positive  \n",
       "0   -0.9948     0.347    0.568     0.085  \n",
       "1    0.9153     0.091    0.660     0.249  \n",
       "2    0.9666     0.143    0.508     0.348  \n",
       "3   -0.9450     0.271    0.663     0.066  \n",
       "4    0.9871     0.034    0.675     0.291  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wosw_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "- Train: 25000 \n",
      "- Validation: 12500 \n",
      "- Test: 12500\n"
     ]
    }
   ],
   "source": [
    "features = df_wosw_sentiment.drop(['num_sentiment', 'review', 'lemma_review'], axis=1)\n",
    "label = df_wosw_sentiment['num_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size = 0.50, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)\n",
    "\n",
    "print(\"Data distribution:\\n- Train: {} \\n- Validation: {} \\n- Test: {}\".format(len(X_train),len(X_val),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7512 0.7576 0.756  0.7514 0.7496]\n",
      "0.75316\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf, X_train, y_train.values.ravel(), cv=5)\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 10, 'n_estimators': 1000}\n",
      "\n",
      "0.7302 for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.75812 for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.75988 for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.75944 for {'max_depth': 2, 'n_estimators': 500}\n",
      "0.75876 for {'max_depth': 2, 'n_estimators': 1000}\n",
      "0.75944 for {'max_depth': 2, 'n_estimators': 3000}\n",
      "0.75532 for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.761 for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.76156 for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.76204 for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.76208 for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.762 for {'max_depth': 10, 'n_estimators': 3000}\n",
      "0.72268 for {'max_depth': 50, 'n_estimators': 5}\n",
      "0.7508 for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.75316 for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.75508 for {'max_depth': 50, 'n_estimators': 500}\n",
      "0.75568 for {'max_depth': 50, 'n_estimators': 1000}\n",
      "0.75552 for {'max_depth': 50, 'n_estimators': 3000}\n",
      "0.72268 for {'max_depth': None, 'n_estimators': 5}\n",
      "0.7508 for {'max_depth': None, 'n_estimators': 50}\n",
      "0.75316 for {'max_depth': None, 'n_estimators': 100}\n",
      "0.75512 for {'max_depth': None, 'n_estimators': 500}\n",
      "0.7556 for {'max_depth': None, 'n_estimators': 1000}\n",
      "0.75548 for {'max_depth': None, 'n_estimators': 3000}\n"
     ]
    }
   ],
   "source": [
    "print_results(gridsearch(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use validation set to select the best parameters\n",
    "rf1 = RandomForestClassifier(n_estimators=1000, max_depth=10)\n",
    "rf1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, max_depth=50)\n",
    "rf2.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rf3.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators=1000, max_depth=None)\n",
    "rf4.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 10, # OF EST: 1000 -- Accuracy: 0.758, Precision: 0.748, Recall: 0.767, F1-Score: 0.758\n",
      "MAX DEPTH: 50, # OF EST: 1000 -- Accuracy: 0.754, Precision: 0.747, Recall: 0.757, F1-Score: 0.752\n",
      "MAX DEPTH: 2, # OF EST: 100 -- Accuracy: 0.753, Precision: 0.747, Recall: 0.754, F1-Score: 0.751\n",
      "MAX DEPTH: None, # OF EST: 1000 -- Accuracy: 0.752, Precision: 0.745, Recall: 0.755, F1-Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "performance(rf1, rf2, rf3, rf4, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 10, # OF EST: 1000 -- Accuracy: 0.769, Precison: 0.767, Recall: 0.782, F1-Score: 0.775\n"
     ]
    }
   ],
   "source": [
    "final_performance(rf1, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Build Model with dataset with stopwords using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Split Dataset which has stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "- Train: 7500 \n",
      "- Validation: 3750 \n",
      "- Test: 3750\n"
     ]
    }
   ],
   "source": [
    "# keep 50% for the training set and 25% both for the validation and the test set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_wsw = pd.read_csv('df_wsw.csv')\n",
    "\n",
    "features = df_wsw.drop(['num_sentiment', 'review'], axis=1)\n",
    "label = df_wsw['num_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size = 0.70, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.50, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)\n",
    "\n",
    "print(\"Data distribution:\\n- Train: {} \\n- Validation: {} \\n- Test: {}\".format(len(X_train),len(X_val),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Create Features using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (7500, 63948)\n",
      "Tfidf_test: (3750, 63948)\n",
      "Tfidf_test: (3750, 63948)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Tfidf vectorizer\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "#transformed train, val, test reviews\n",
    "tv_train=tv.fit_transform(X_train['lemma_review'])\n",
    "tv_val=tv.transform(X_val['lemma_review'])\n",
    "tv_test=tv.transform(X_test['lemma_review'])\n",
    "\n",
    "print('Tfidf_train:', tv_train.shape)\n",
    "print('Tfidf_test:', tv_val.shape)\n",
    "print('Tfidf_test:', tv_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81933333 0.83733333 0.82133333 0.80866667 0.832     ]\n",
      "0.8237333333333334\n"
     ]
    }
   ],
   "source": [
    "# Base Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf,tv_train,y_train.values.ravel(),cv=5)\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': None, 'n_estimators': 1000}\n",
      "\n",
      "0.57813 for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.71107 for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.74933 for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.79467 for {'max_depth': 2, 'n_estimators': 500}\n",
      "0.8016 for {'max_depth': 2, 'n_estimators': 1000}\n",
      "0.8052 for {'max_depth': 2, 'n_estimators': 3000}\n",
      "0.66747 for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.79093 for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.806 for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.83253 for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.83227 for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.8348 for {'max_depth': 10, 'n_estimators': 3000}\n",
      "0.67947 for {'max_depth': 50, 'n_estimators': 5}\n",
      "0.80627 for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.82853 for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.8396 for {'max_depth': 50, 'n_estimators': 500}\n",
      "0.8436 for {'max_depth': 50, 'n_estimators': 1000}\n",
      "0.84373 for {'max_depth': 50, 'n_estimators': 3000}\n",
      "0.6724 for {'max_depth': None, 'n_estimators': 5}\n",
      "0.80107 for {'max_depth': None, 'n_estimators': 50}\n",
      "0.82373 for {'max_depth': None, 'n_estimators': 100}\n",
      "0.84053 for {'max_depth': None, 'n_estimators': 500}\n",
      "0.84493 for {'max_depth': None, 'n_estimators': 1000}\n",
      "0.84387 for {'max_depth': None, 'n_estimators': 3000}\n"
     ]
    }
   ],
   "source": [
    "print_results(gridsearch(tv_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use validation set to select the best parameters\n",
    "rf1 = RandomForestClassifier(n_estimators=1000, max_depth=None)\n",
    "rf1.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=500, max_depth=50)\n",
    "rf2.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=500, max_depth=10)\n",
    "rf3.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators=500, max_depth=None)\n",
    "rf4.fit(tv_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: None, # OF EST: 1000 -- Accuracy: 0.826, Precision: 0.834, Recall: 0.822, F1-Score: 0.828\n",
      "MAX DEPTH: 50, # OF EST: 500 -- Accuracy: 0.827, Precision: 0.835, Recall: 0.825, F1-Score: 0.83\n",
      "MAX DEPTH: 10, # OF EST: 500 -- Accuracy: 0.821, Precision: 0.806, Recall: 0.855, F1-Score: 0.83\n",
      "MAX DEPTH: None, # OF EST: 500 -- Accuracy: 0.82, Precision: 0.826, Recall: 0.819, F1-Score: 0.823\n"
     ]
    }
   ],
   "source": [
    "performance(rf1, rf2, rf3, rf4, tv_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 50, # OF EST: 500 -- Accuracy: 0.848, Precison: 0.848, Recall: 0.84, F1-Score: 0.844\n"
     ]
    }
   ],
   "source": [
    "final_performance(rf2, tv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Build Model with dataset without stopwords using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Split Dataset which do not have stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution:\n",
      "- Train: 7500 \n",
      "- Validation: 3750 \n",
      "- Test: 3750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_wosw = pd.read_csv('df_wosw.csv')\n",
    "\n",
    "features = df_wosw.drop(['num_sentiment', 'review'], axis=1)\n",
    "label = df_wosw['num_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size = 0.70, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.50, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)\n",
    "\n",
    "print(\"Data distribution:\\n- Train: {} \\n- Validation: {} \\n- Test: {}\".format(len(X_train),len(X_val),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create Features using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (7500, 63728)\n",
      "Tfidf_test: (3750, 63728)\n",
      "Tfidf_test: (3750, 63728)\n"
     ]
    }
   ],
   "source": [
    "tv = TfidfVectorizer()\n",
    "\n",
    "tv_train=tv.fit_transform(X_train['lemma_review'])\n",
    "tv_val=tv.transform(X_val['lemma_review'])\n",
    "tv_test=tv.transform(X_test['lemma_review'])\n",
    "\n",
    "print('Tfidf_train:',tv_train.shape)\n",
    "print('Tfidf_test:',tv_val.shape)\n",
    "print('Tfidf_test:',tv_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.834      0.85266667 0.84866667 0.81066667 0.84      ]\n",
      "0.8371999999999999\n"
     ]
    }
   ],
   "source": [
    "# Base Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "scores = cross_val_score(rf,tv_train,y_train.values.ravel(),cv=5)\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'max_depth': 50, 'n_estimators': 3000}\n",
      "\n",
      "0.5864 for {'max_depth': 2, 'n_estimators': 5}\n",
      "0.72227 for {'max_depth': 2, 'n_estimators': 50}\n",
      "0.75947 for {'max_depth': 2, 'n_estimators': 100}\n",
      "0.792 for {'max_depth': 2, 'n_estimators': 500}\n",
      "0.8032 for {'max_depth': 2, 'n_estimators': 1000}\n",
      "0.80813 for {'max_depth': 2, 'n_estimators': 3000}\n",
      "0.66947 for {'max_depth': 10, 'n_estimators': 5}\n",
      "0.79853 for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.81747 for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.836 for {'max_depth': 10, 'n_estimators': 500}\n",
      "0.83853 for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.84213 for {'max_depth': 10, 'n_estimators': 3000}\n",
      "0.7116 for {'max_depth': 50, 'n_estimators': 5}\n",
      "0.822 for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.83733 for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.85067 for {'max_depth': 50, 'n_estimators': 500}\n",
      "0.85293 for {'max_depth': 50, 'n_estimators': 1000}\n",
      "0.85747 for {'max_depth': 50, 'n_estimators': 3000}\n",
      "0.71013 for {'max_depth': None, 'n_estimators': 5}\n",
      "0.81813 for {'max_depth': None, 'n_estimators': 50}\n",
      "0.8372 for {'max_depth': None, 'n_estimators': 100}\n",
      "0.8508 for {'max_depth': None, 'n_estimators': 500}\n",
      "0.85027 for {'max_depth': None, 'n_estimators': 1000}\n",
      "0.8532 for {'max_depth': None, 'n_estimators': 3000}\n"
     ]
    }
   ],
   "source": [
    "print_results(gridsearch(tv_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=50, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use validation set to select the best parameters\n",
    "rf1 = RandomForestClassifier(n_estimators=3000, max_depth=50)\n",
    "rf1.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=3000, max_depth=None)\n",
    "rf2.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf3 = RandomForestClassifier(n_estimators=3000, max_depth=10)\n",
    "rf3.fit(tv_train, y_train.values.ravel())\n",
    "\n",
    "rf4 = RandomForestClassifier(n_estimators=1000, max_depth=50)\n",
    "rf4.fit(tv_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: 50, # OF EST: 3000 -- Accuracy: 0.833, Precision: 0.839, Recall: 0.834, F1-Score: 0.836\n",
      "MAX DEPTH: None, # OF EST: 3000 -- Accuracy: 0.833, Precision: 0.841, Recall: 0.829, F1-Score: 0.835\n",
      "MAX DEPTH: 10, # OF EST: 3000 -- Accuracy: 0.826, Precision: 0.802, Recall: 0.874, F1-Score: 0.837\n",
      "MAX DEPTH: 50, # OF EST: 1000 -- Accuracy: 0.828, Precision: 0.833, Recall: 0.829, F1-Score: 0.831\n"
     ]
    }
   ],
   "source": [
    "performance(rf1, rf2, rf3, rf4, tv_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX DEPTH: None, # OF EST: 3000 -- Accuracy: 0.852, Precison: 0.849, Recall: 0.849, F1-Score: 0.849\n"
     ]
    }
   ],
   "source": [
    "final_performance(rf2, tv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
